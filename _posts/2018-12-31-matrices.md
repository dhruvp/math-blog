---
layout: post
title: The Intuition Behind Matrices
comments: false

---
{% katexmm %}

Many of us have probably encountered matrices at some point in math. They're these awkward tables with seemingly byzantine rules for combining them. Take the first element of the first row, first element of the first column, multiply them together, then add... If that isn't strange I don't know what is.

 We all probably learned how to operate on them at some point but how did someone come up with the idea of matrices and the rules for operating on them? In short, what's the underlying intuition for matrices?

I really think these questions are worth answering as we use matrices in almost every field of engineering but often lack an intuition for them. To me it's not too different from applying multiplication tables without fully appreciating what numbers are.

So let's build this intuition! Through this post, I'm going to share my understanding of matrices and why I think they represent such a powerful idea.

## Linear Maps

Before delving into matrices, we need to first start with Linear Maps. Linear Maps are the foundations of matrices. Here's a simple example of a linear map:

* $f(x) = 3x$ for real numbers $x$.

Linear maps are functions that have these basic rules (I'm simplifying a little here. If you wan't the precise definition, see [here](https://en.wikipedia.org/wiki/Linear_map).) 

1. $ f(c \cdot x) = c \cdot f(x) $
   * You can multiply by a scalar before or after applying the function and get the same result.
   * For our example function, $f(5\cdot x) = 3 \cdot 5x = 15x = 5 \cdot f(x)$.
2. $ f(x+y) = f(x) + f(y) $
   * You can add before or after applying the function and get the same result.
   * For our example function, $f(x + y) = 3 \cdot (x + y) = 3x + 3y = f(x) + f(y)$.

Early mathematicians realized that such functions can model a lot of the phenomena that happen in the real world from physics, to statistics. Here are a few other examples of linear maps in geometry:
* Rotations
   * Functions that rotate shapes around a point.
   * <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/87/Rotation_illustration2.svg/1920px-Rotation_illustration2.svg.png" width="80%"/>
* Scalings
   * Functions that takes a 2d image and scale their width and/or height.
   * ![scaling example](https://developer.apple.com/library/archive/documentation/Cocoa/Conceptual/CocoaDrawingGuide/Art/scaling_2x.png)

## Representing Functions
So we now know what linear maps are and we've seen how they represent many physical phenomena - but how can we represent them? Taking a step back, how do we represent functions in general?

One way is to simply have a table that takes every input and displays its output. For instance, for a function $f$ we could write:

|  $x$  |  $f(x)$ |
:----:|:------:
|  1  |  2  |
|  2  |  4  |
|  3  |  6  |

But this can much more easily be written as $f(x) = 2x$. This representation, a polynomial, is powerful. How? For example let's say I have another function $g(x) = 10x$. Imagine someone asks me, “what happens if I apply $f$, followed by $g$?"

Before I had this representation, I would have had to make a full table where I write out f(x), and then apply g(x) on it per input like below:

|  $x$  |  $f(x)$ |  $g(f(x))$ |
:----:|:---:|:------------:|
|  1  |  2  |      20    |
|  2  |  4  |      40    |
|  3  |  6  |      60    |

But now that we have a the polynomial representation, we can just do
$$g(x) = 10x$$
$$g(f(x)) = 10\cdot f(x)$$
$$g(f(x)) = 10\cdot 2x$$
$$g(f(x)) = 20x$$

In a few simple steps, we could immediately figure out $g(f(x))$. The same is true of $g(x) + f(x)$ etc.

In short, the right representation allows us to understand, combine, and process functions in extremely powerful ways.

### Representing Linear Maps

Returning to linear maps, how can we easily represent them equally succinctly?

#### 1-Dimension

Let's start with linear maps that take in real numbers and return real numbers (all in 1 dimension - the real line).

<p class='image-block'>
<img src="https://upload.wikimedia.org/wikipedia/commons/2/2b/Real_number_line_for_Algebra_book.svg">
Let's start with linear maps that take inputs on the real line and return outputs on the real line
</p>

These linear transforms can always be written simply as $f(x) = mx$ for some $m$. Pretty simple!

#### 2-Dimensions

But what about in 2 dimensions (i.e. the input is a vector such as $\textcolor{blue}{\begin{bmatrix}
1 \\ 0 \end{bmatrix}}$)?

<p class='image-block'>
<img src="https://i.stack.imgur.com/TKyga.png"/>
Now, let's focus on linear maps that operate on 2d vectors.
</p>


Let's take a new function $f(x)$.
Let’s just start by describing what the function does to two of the most basic vectors $\textcolor{blue}{\begin{bmatrix} 1 \\ 0 \end{bmatrix}}$ and $\textcolor{#228B22}{\begin{bmatrix} 0 \\ 1 \end{bmatrix}}$.

We define:

$$f(\textcolor{blue}{\begin{bmatrix}1 \\0\end{bmatrix}}) = \begin{bmatrix} 3 \\ 0\end{bmatrix}$$
$$f(\textcolor{#228B22}{\begin{bmatrix}0 \\1\end{bmatrix}}) = \begin{bmatrix}0 \\5\end{bmatrix}$$

Based on this, can we figure out $f\begin{bmatrix}
\textcolor{blue}{10} \\
\textcolor{#228B22}{9}\end{bmatrix}$ is? Amazingly, yes!

------

The below diagram is going to show our approach visually:

<p class='image-block'>
<img src="/public/images/vector_img.png"/>
We will decompose $\begin{bmatrix} \textcolor{blue}{10} \\ \textcolor{#228B22}{9}\end{bmatrix}$ into a combination of $\textcolor{blue}{\begin{bmatrix} 1 \\ 0\end{bmatrix}})$ and $\textcolor{#228B22}{\begin{bmatrix} 0 \\1\end{bmatrix})}$ (the two vectors which we know the value of $f$ for).
</p>

More precisely, here's how we find the final value: 

$$f(\begin{bmatrix} \textcolor{blue}{10} \\ \textcolor{#228B22}{9}\end{bmatrix}) = f(\begin{bmatrix} \textcolor{blue}{10} \\ 0\end{bmatrix}) + f(\begin{bmatrix} 0 \\ \textcolor{#228B22}{9}\end{bmatrix})$$

$$ = 10 \cdot f( \textcolor{blue}{\begin{bmatrix}1 \\0\end{bmatrix})} + 9 \cdot f(\textcolor{#228B22}{\begin{bmatrix} 0 \\ 1 \end{bmatrix})}$$
$$ = 10 \cdot \textcolor{blue}{\begin{bmatrix} 3 \\ 0 \end{bmatrix}} + 9\cdot \textcolor{#228B22}{\begin{bmatrix} 0 \\ 5 \end{bmatrix}}$$
$$ = \textcolor{blue}{\begin{bmatrix} 30 \\ 0 \end{bmatrix}} + \textcolor{#228B22}{\begin{bmatrix} 0 \\ 45 \end{bmatrix}}$$
$$ = \begin{bmatrix}
30 \\
45
\end{bmatrix}$$


So we're able to find $f(\begin{bmatrix}\textcolor{blue}{10} \\ \textcolor{#228B22}{9}\end{bmatrix})$ by just knowing $f(\textcolor{blue}{\begin{bmatrix} 1 \\ 0\end{bmatrix})}$ and $f(\textcolor{#228B22}{\begin{bmatrix} 0 \\ 1\end{bmatrix}})$.

**In fact this is true more generally - we can represent the function entirely by what it does to the vectors $\textcolor{blue}{\begin{bmatrix}1 \\0\end{bmatrix}}$ and $\textcolor{#228B22}{\begin{bmatrix}0 \\1 \end{bmatrix}}$ and use that to find all potential outputs!**


### Matrices

So is there a way I can quickly say what a linear function does to $\textcolor{blue}{\begin{bmatrix}
1 \\
0
\end{bmatrix}}$ and 
$\textcolor{#228B22}{\begin{bmatrix}
0 \\
1
\end{bmatrix}}$?

Yes! A simple 2x2 matrix!


$f(x)$ (as we defined it in the previous section) can be represented by the notation
$$\begin{bmatrix} f(\textcolor{blue}{\begin{bmatrix} 1 \\ 0 \end{bmatrix}}) & f(\textcolor{#228B22}{\begin{bmatrix} 0 \\ 1 \end{bmatrix}}) \end{bmatrix}$$
$$ = \begin{bmatrix} \textcolor{blue}{3} & \textcolor{#228B22}{0} \\ \textcolor{blue}{0} & \textcolor{#228B22}{5} \end{bmatrix} $$

This is extremely cool - we can describe the entire function and how it operates on an infinite number of points by a little 4 value table.


So just like whenever you see $f(x) = 2x + 3$, you immediately know you’re dealing with a function, **when you see a matrix, know that you are dealing with a linear function**.

### Applying the Function
Ok so we know we can represent a linear function as a matrix - but how do we apply this function on an input?

Specifically, say I have the same function $f$ which we described by the matrix $F =  \begin{bmatrix} \textcolor{blue}{3} & \textcolor{#228B22}{0} \\ \textcolor{blue}{0} & \textcolor{#228B22}{5} \end{bmatrix} $. I want to apply this function on the vector $ \begin{bmatrix} \textcolor{blue}{x} \\ \textcolor{#228B22}{y} \end{bmatrix} $. How do we do it?

------

Let’s start with what we know:

1. The first column of the matrix tells us $f(\textcolor{blue}{\begin{bmatrix} 1 \\ 0 \end{bmatrix}})$ .
2. the second column tells us $f(\textcolor{#228B22}{\begin{bmatrix} 0 \\ 1 \end{bmatrix}})$.


To make use of that, let's break $\begin{bmatrix} \textcolor{blue}{x} \\ \textcolor{#228B22}{y} \end{bmatrix}$ into a combination of $\textcolor{blue}{\begin{bmatrix} 1 \\ 0 \end{bmatrix}}$ and $\textcolor{#228B22}{\begin{bmatrix}0 \\ 1 \end{bmatrix}}$.

$$\begin{bmatrix} \textcolor{blue}{x} \\ \textcolor{#228B22}{y} \end{bmatrix} = x \cdot \textcolor{blue}{\begin{bmatrix} 1 \\ 0 \end{bmatrix}} + y \cdot \textcolor{#228B22}{\begin{bmatrix} 0 \\ 1 \end{bmatrix}}$$

$$ f(\begin{bmatrix} \textcolor{blue}{x} \\ \textcolor{#228B22}{y} \end{bmatrix}) = f(x \cdot \textcolor{blue}{\begin{bmatrix} 1 \\ 0 \end{bmatrix}}) + y \cdot \textcolor{#228B22}{\begin{bmatrix} 0 \\ 1 \end{bmatrix}})$$

Thanks to the amazing properties of linear maps ($f(a+b) = f(a) + f(b)$), we can now simplify this to:

$$ = f(x \cdot \textcolor{blue}{\begin{bmatrix} 1 \\ 0 \end{bmatrix}}) + f(y \cdot \textcolor{#228B22}{\begin{bmatrix} 0 \\ 1 \end{bmatrix}})$$

And then using another property of linear maps ($f(c \cdot a) = c\cdot f(a)$),

$$ = x\cdot f(\textcolor{blue}{\begin{bmatrix} 1 \\ 0 \end{bmatrix}}) + y \cdot f(\textcolor{#228B22}{\begin{bmatrix} 0 \\ 1 \end{bmatrix}})$$

And now we apply the knowledge we have (from the columns of the matrix)!

$$ = x \cdot \textcolor{blue}{\begin{bmatrix} 3 \\ 0 \end{bmatrix}} + y\cdot \textcolor{#228B22}{\begin{bmatrix} 0 \\ 5 \end{bmatrix}}$$
$$f(\begin{bmatrix} \textcolor{blue}{x} \\ \textcolor{#228B22}{y} \end{bmatrix}) = \begin{bmatrix} 3x + 0y \\ 0x + 5y \end{bmatrix}$$

Does this look familiar? Because it is exactly what you would get by carrying out the matrix multiplication $\begin{bmatrix} \textcolor{blue}{3} & \textcolor{#228B22}{0} \\ \textcolor{blue}{0} & \textcolor{#228B22}{5} \end{bmatrix} \cdot \begin{bmatrix} \textcolor{blue}{x} \\ \textcolor{#228B22}{y} \end{bmatrix}$!

**The matrix multiplication rule is just a shorthand for applying a function on a vector!**

### Matrix Multiplication as Function Composition

Ok so we’ve seen that multiplying a 2x2 matrix by a vector is just applying the function on the vector. But what does matrix multiplication when we are multiplying two 2x2 matrices?

To answer this, we’re going to take a small detour. We know how to apply a function $f$ on an input vector $v$. What if I ask you to find the composition $h = g(f(v))$ where we know $f$ and $g$?


---------


Let’s work through this now:

1. Let $G$ be the matrix for the function $g$.
2. Let $F$ be the matrix for function $f$.


We want to find the matrix $H$ that represents the function $h = g(f(v))$.

This is going to be:

$$H = \begin{bmatrix} g(f(\textcolor{blue}{\begin{bmatrix} 1 \\ 0 \end{bmatrix}}) & g(f(\textcolor{#228B22}{\begin{bmatrix} 0 \\ 1 \end{bmatrix}})) \end{bmatrix}$$

Let $\textcolor{blue}{F_{col1}}$ be the first column of $F$ and let $\textcolor{#228B22}{F_{col2}}$ be the second column.

Then we can simplify to:

$$H = \begin{bmatrix} g(\textcolor{blue}{F_{col1}}) & g(\textcolor{#228B22}{F_{col2}}) \end{bmatrix} $$

So what’s $g(\textcolor{blue}{F_{col1}})$?

Well we just saw earlier that this is just $G \cdot \textcolor{blue}{F_{col1}}$. So we can now write:

$$H = \begin{bmatrix} G \cdot \textcolor{blue}{F_{col1}} & G \cdot \textcolor{#228B22}{F_{col2}} \end{bmatrix} $$

Seem familiar? Because it’s exactly what the formula for the 2x2 matrix multiplication $H = G\cdot F$! So $H$, the matrix representing $g(f(x))$, is just $G\cdot F$.

**Clearly, matrix multiplication can be thought of as function composition.**


### An Example of Function Composition

Let's work through a full example to see this function composition in action.

1. Let $f$ be our function as earlier (represented by the matrix $F = \begin{bmatrix}3 & 0 \\ 0 & 5\end{bmatrix}$).
2. Let $g$ be a function that rotates a vector 90º counter-clockwise.

-----

##### $g$ Composed With $f$
Let's work through $h = g \circ f$ applied on the vector $v = \begin{bmatrix} 2 \\ 1\end{bmatrix}$. We can use just the properties of $f$ and $g$ to figure out this result (see diagram below).

1. We start with $v$.
2. We know $f$ stretches its input by $3x$ in the x direction and by $5x$ in the y direction, leading to $f(v) = \begin{bmatrix} 6 \\ 5 \end{bmatrix}$.
3. We then just rotate the resulting matrix to $g(f(v)) = \begin{bmatrix} -5 \\ 6 \end{bmatrix}$.

<img src="/public/images/composition_steps.png" width="80%">

-----

##### $g$ Composed With $f$ Using Matrices

Do we get the same result when using function composition through matrices? To find out we need to first find the matrix representation of $g$.

-----

##### The Matrix representation of $g$

Let's as earlier start with just understanding $g$ on our two basic vectors $\textcolor{blue}{\begin{bmatrix}1 \\ 0\end{bmatrix}}$ and $\textcolor{#228B22}{\begin{bmatrix}0 \\ 1 \end{bmatrix}}$.


1. $\textcolor{blue}{\begin{bmatrix} 1 \\ 0\end{bmatrix}}$ turned 90º counterclockwise is $\begin{bmatrix}0 \\ 1\end{bmatrix}$.
<img src="/public/images/rotation_1_0.png" width="70%"/>

2. $\textcolor{#228B22}{\begin{bmatrix} 0 \\ 1\end{bmatrix}}$ turned 90º counterclockwise is $\begin{bmatrix}-1 \\ 0\end{bmatrix}$.
<img src="/public/images/rotation_0_1.png" width="70%"/>

Therefore, $G$, the matrix representation of $g$, is $G = \begin{bmatrix} \textcolor{blue}{0} & \textcolor{#228B22}{-1} \\ \textcolor{blue}{1} & \textcolor{#228B22}{0} \end{bmatrix}$.

##### Returning to $g$ composed with $f$ Using Matrices


1. The matrix for $g \circ f$ is $H = G \cdot F$.
2. $H = G \cdot F = \begin{bmatrix} 0 & -1 \\ 1 & 0 \end{bmatrix} \begin{bmatrix} 3 & 0 \\ 0 & 5 \end{bmatrix} = \begin{bmatrix} 0 & -5 \\ 3 & 0 \end{bmatrix}$
4. To apply $H$ on the vector $v$ we just do $H \cdot v$.
5. $H \cdot v = \begin{bmatrix} 0 & -5 \\ 3 & 0 \end{bmatrix} \begin{bmatrix} 2 \\ 1 \end{bmatrix}  = \begin{bmatrix} -5 \\ 6 \end{bmatrix}$.

This is exactly what we got when visually applying $g(f(v))$. This once again shows that matrix multiplication is just a quick way of finding the composition of linear maps.

-----

### Big Picture: Matrices Give Us Power

Remember how much power we gained by being able to represent a function as a polynomial? We were able to combine polynomials, compose them, multiply them - we now have all that same power for linear maps! We can compose them (matrix multiplication), add them (matrix addition), and invert them (matrix inversion) all by following some simple rules.

A more sophisticated way of saying this is we have an algebra on these functions (just like we have an algebra on integers etc.). **This is what linear algebra broadly means - the ability to do combine and compose linear maps just as we combine and compose integers.**


### Looking Forward
So we’ve seen pretty clearly that matrices are just functions and that linear algebra is the study of combining linear maps.

Understanding this helps us perceive some of the key ideas of linear algebra in a new way. In the next post, we’re going to focus on eigenvectors and learn why they are so useful in playing with these functions.


{% endkatexmm %}