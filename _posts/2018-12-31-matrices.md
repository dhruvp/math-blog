---
layout: post
title: An intuitive understanding of matrices
comments: false

---
{% katexmm %}

## Matrices and their Intuition

Many of us have probably encountered matrices at some point but in math class. They're this little awkward tables with seemingly byzantine rules for multiplying and inverting them. We all probably learned how to operate on them at some point but how did someone come up with them? Where do these rules for multiplication and inversion even come from? In short, what's the underlying intuition for matrices?

I really think it's worth answering this question because we use matrices in almost every field of engineering but often times don't appreciate what they mean. To me it's not too different from applying multiplication tables without fully appreciating what numbers are.

So let's try and rectify that a litte. Through this post, I'm going to share my intuition of matrices and why they represent such a powerful idea. We’re going to do so by starting with the idea of linear functions and then using that knowledge to derive matrices.


## Linear functions

Linear functions are the foundations of matrices. Before diving into what they are, let’s start really simply by focusing on one specific example and moving up from there.

Let’s take the function that reflects lines about the y axis.

[INSERT DIAGRAM HERE]

What are some interesting things to note about this function?
1. I can multiply by a number before or after applying the function and I’ll get the same result.
Show example
2. I can add before or after applying the function and I’ll get the same result.
Show example

In fact, there are a lot of functions that obey these rules. Here are a few more:
* Rotations
* Scaling

Early mathematicians realized that such functions can model a lot of the phenomena that happen in the real world from physics, to statistics. We call these functions linear functions (not to be confused with a linear equation) and their main rules are as follows:
* $ f(c \cdot x) = c \cdot f(x) $
   * Can multiply before or after applying the function and get the same result.
* $ f(x+y) = f(x) + f(y) $
   * Can add before or after applying the function and get the same result.

## Geometric Interpretation of Linear Functions
What do these linear functions look like? Here are a few videos from [3 Blue 1 Brown's Youtube Channel](https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw) visualizing their effect.

#### 1-dimensional linear functions

<iframe width="560" height="315" src="https://www.youtube.com/embed/xnLx3aZOpCE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

#### 2-dimensional linear functions

<iframe width="560" height="315" src="https://www.youtube.com/embed/2xKaXDHDGsA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

## Representing Functions
We now know what linear functions are - but how can we succintly represent them? Taking a step back, how do we represent functions in general? One way is to simply have a table that takes every input and displays its output. For instance, we could write:

|  x  |  f(x) |
------|--------
|  1  |  2  |
|  2  |  4  |
|  3  |  6  |

But this can much more easily be written as $ f(x) = 2x $. This representation, a polynomial, is powerful. How? For example let's say I have another function $g(x) = 10x$. Imagine someone asks me, “what happens if I apply $f$, followed by $g$?"

Before I had this representation, I would have had to make a full table where I write out f(x), and then apply g(x) on it per input like below:

|  x  |  f(x) |  g(f(x)) |
------|-------------------
|  1  |  2  |      20    |
|  2  |  4  |      40    |
|  3  |  6  |      60    |

But now that we have a the polynomial representation, we can just do
$$g(x) = 10x$$
$$g(f(x)) = 10f(x)$$
$$g(f(x)) = 10\cdot 2x$$
$$g(f(x)) = 20x$$

Now, in a few simple steps, immediately figure out $g(f(x))$. The same is true of $g(x) + f(x)$, $g(x) \cdot f(x)$ etc.

In short, the right representation allows us to succintly understand, combine, and process functions in extremely powerful ways.

### Representing Linear Functions

Returning to linear functions, how can we easily represent them?

#### 1-dimension

Let's start with linear functions that take in real numbers and return real numbers (all in 1 dimension - the real line).

<p class='image-block'>
<img src="https://upload.wikimedia.org/wikipedia/commons/2/2b/Real_number_line_for_Algebra_book.svg">
Let's start with linear functions that take inputs on the real line and return outputs on the real line
</p>

These linear transforms will always be written simply as $f(x) = mx$ for some $m$. So the representation for linear functions that operate in one dimension is easy.

#### 2-dimensions

But what about in 2 dimensions (i.e. the input is a vector $\begin{bmatrix}
1 \\
0
\end{bmatrix}$)?

<p class='image-block'>
<img src="https://i.stack.imgur.com/TKyga.png"/>
Now, let's focus on linear functions that operate on 2d vectors.
</p>


Let's take a new function $f(x)$.
Let’s just start by describing what the function does to two of the most basic vectors:

$\begin{bmatrix}
1 \\
0
\end{bmatrix}$ and 
$\begin{bmatrix}
0 \\
1
\end{bmatrix}$.

$$f(\begin{bmatrix}
1 \\
0
\end{bmatrix}) = \begin{bmatrix}
3 \\
0
\end{bmatrix}$$
$$f(\begin{bmatrix}
0 \\
1
\end{bmatrix}) = \begin{bmatrix}
0 \\
5
\end{bmatrix}$$

Based on this, can I figure out $f\begin{bmatrix}
10 \\
9\end{bmatrix}$ is? Amazingly, yes! Because this is a linear function, we see that 

$$f(\begin{bmatrix}
10 \\
9\end{bmatrix}) = f(\begin{bmatrix}
10 \\
0\end{bmatrix}) + f(\begin{bmatrix}
0 \\
9\end{bmatrix})$$
$$ = 10 \cdot f(\begin{bmatrix}
1 \\
0
\end{bmatrix}) + 9 \cdot f(\begin{bmatrix} 0 \\ 1 \end{bmatrix})$$
$$ = 10 \cdot \begin{bmatrix} 3 \\ 0 \end{bmatrix} + 9\cdot \begin{bmatrix} 0 \\ 5 \end{bmatrix}$$
$$ = \begin{bmatrix} 30 \\ 0 \end{bmatrix} + \begin{bmatrix} 0 \\ 45 \end{bmatrix}$$
$$ = \begin{bmatrix}
30 \\
45
\end{bmatrix}$$


**What this shows is that we can represent the function entirely by what it does to the vectors $\begin{bmatrix}
1 \\
0
\end{bmatrix}$ and 
$\begin{bmatrix}
0 \\
1
\end{bmatrix}$.**

I would put this sentence before your actual multiplication above ^ and then draw visual diagrams from f(10,9) to the (1,0) and (0,1) former and latter 1’s specifically. As a visual learner the diagram would help connect the dots much faster.

#### Matrices

Ok so is there a way I can succintly describe what a function does to $\begin{bmatrix}
1 \\
0
\end{bmatrix}$ and 
$\begin{bmatrix}
0 \\
1
\end{bmatrix}$?

Yes!

A simple 2x2 matrix can do just this!


$f(x)$ can be represented by the notation
$$\begin{bmatrix} f(\begin{bmatrix} 1 \\ 0 \end{bmatrix}) & f(\begin{bmatrix} 0 \\ 1 \end{bmatrix}) \end{bmatrix}$$
$$ \begin{bmatrix} 3 & 0 \\ 0 & 5 \end{bmatrix} $$

This is extremely cool - we can describe the entire function and how it operates on an infinite number of points by a little 4 value table.


So just like whenever you see $f(x) = 2x + 3$, you immediately know you’re dealing with a function, **next time you see a matrix, know that you are dealing with a shorthand for a linear function**. It’s the $f(x) = mx$ of the linear world.

#### Understanding Matrix Multiplication
Ok so we know that a matrix represents a function - but how do we apply this function on an input?

Specifically, say I have the same function $f$ which we described by the matrix $F =  \begin{bmatrix} 3 & 0 \\ 0 & 5 \end{bmatrix} $. I want to apply this function on the vector $ \begin{bmatrix} x \\ y \end{bmatrix} $. How do we do it?

Let’s start with what we know. The first column of the matrix tells us $f(\begin{bmatrix} 1 \\ 0 \end{bmatrix})$ and the second column tells us $f(\begin{bmatrix} 0 \\ 1 \end{bmatrix})$.

To make use of that, let's break $\begin{bmatrix} x \\ y \end{bmatrix}$ into a combination of $\begin{bmatrix} 1 \\ 0 \end{bmatrix}$ and $\begin{bmatrix} 0 \\ 1 \end{bmatrix}$.

$$\begin{bmatrix} x \\ y \end{bmatrix} = x \cdot \begin{bmatrix} 1 \\ 0 \end{bmatrix} + y \cdot \begin{bmatrix} 0 \\ 1 \end{bmatrix}$$

$$ f(\begin{bmatrix} x \\ y \end{bmatrix}) = f(x \cdot \begin{bmatrix} 1 \\ 0 \end{bmatrix}) + y \cdot \begin{bmatrix} 0 \\ 1 \end{bmatrix})$$

Thanks to the amazing properties of linear functions ($f(a+b) = f(a) + f(b)$), we can now simplify this to:

$$ = f(x \cdot \begin{bmatrix} 1 \\ 0 \end{bmatrix}) + f(y \cdot \begin{bmatrix} 0 \\ 1 \end{bmatrix})$$

And then using another property of linear functions ($f(c \cdot a) = c\cdot f(a)$),

$$ = x\cdot f(\begin{bmatrix} 1 \\ 0 \end{bmatrix}) + y \cdot f(\begin{bmatrix} 0 \\ 1 \end{bmatrix})$$

And now we apply the knowledge we have (from the columns of the matrix)!

$$ = x \cdot \begin{bmatrix} 3 \\ 0 \end{bmatrix} + y\cdot \begin{bmatrix} 0 \\ 5 \end{bmatrix}$$
$$f(\begin{bmatrix} x \\ y \end{bmatrix}) = \begin{bmatrix} 3x + 0y \\ 0x + 5y \end{bmatrix}$$

Does this look familiar? Because it is exactly what you would get by carrying out the matrix multiplication $\begin{bmatrix} 3 & 0 \\ 0 & 5 \end{bmatrix} \cdot \begin{bmatrix} x \\ y \end{bmatrix}$!

The matrix multiplication rule is just a shorthand for applying a function on a vector! This is really what's happening under the scenes.

#### Matrix Multiplication as Function Composition

Ok so we’ve seen that multiplying a 2x2 matrix by a vector is just applying the function on the vector. But what does matrix multiplication when we are multiplying two 2x2 matrices?

To answer this, we’re going to take a small detour. We know how to apply a function $f$ on an input vector $v$. What if I ask you to find the composition $h = g(f(v))$ where we know $f$ and $g$?

Let’s work through this now:

Let $G = \begin{bmatrix} 5 & 9 \\ 1 & 6 \end{bmatrix}$ (G is the matrix for the function g).

Let $F = \begin{bmatrix} 3 & 0 \\ 0 & 5 \end{bmatrix}$ as before.


We want to find the matrix $H$ that represents the function $h = g(f(v))$.

This is going to be:

$$H = \begin{bmatrix} g(f(\begin{bmatrix} 1 \\ 0 \end{bmatrix}) & g(f(\begin{bmatrix} 0 \\ 1 \end{bmatrix})) \end{bmatrix}$$
$$H = \begin{bmatrix} g(\begin{bmatrix} 3 \\ 0 \end{bmatrix}) & g(\begin{bmatrix} 0 \\ 5 \end{bmatrix}) \end{bmatrix} $$

So what’s $g(\begin{bmatrix} 3 \\ 0 \end{bmatrix})$?

Well we just saw earlier that this is just $G \cdot (\begin{bmatrix} 3 \\ 0 \end{bmatrix})$. So we can now write:

$$H = \begin{bmatrix} G \cdot \begin{bmatrix} 3 \\ 0 \end{bmatrix} & G \cdot \begin{bmatrix} 0 \\ 5 \end{bmatrix} \end{bmatrix} $$

Seem familiar? Because it’s exactly what the formula for the 2x2 matrix multiplication $H = G\cdot F$! **This shows that matrix multiplication can be thought of as function composition.**

Thanks to matrix multiplication, we have amazingly simple rules for understanding $f\cdot g$, $f+g$ etc. without manually writing out a bunch of tables.

### Combining Functions

Remember how much power we gained by being able to represent a function as a polynomial? We were able to combine polynomials, compose them, multiply them - we now have all that same power for linear functions! We can compose them (matrix multiplication), add them (matrix addition), and invert them (matrix inversion) all by following some simple rules.

A more sophisticated way of saying this is we have an algebra on these functions (just like we have an algebra on integers etc.). **This is what linear algebra means - the ability to do combine and compose linear functions just as we combine and compose integers.**

Imagine doing all this with input-output tables! It would be hell. Instead, we can now operate on these complex functions and combine them in all kinds of ways and immediately know the resulting function.

### Looking Forward
So we’ve seen pretty clearly that matrices are just functions and that linear algebra is the study of combining linear functions.

Understanding this helps us perceive some of the key ideas of linear algebra in a new way. In the next post, we’re going to focus on eigenvectors and learn why they are so useful in playing with these functions.


{% endkatexmm %}