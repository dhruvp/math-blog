---
layout: post
title: The Intuition Behind Matrices
comments: false

---
{% katexmm %}

<p class='image-block'>
<img src="https://cdn3.movieweb.com/i/article/gIdrZFTvO1nsC16dRaTBMOzqaabBjj/798:50/The-Matrix-4-Reboot-Plot-Keanu-Reeves.jpg"/>
Please teach me Keanu.
</p>

Many of us have probably encountered matrices at some point in math. They're these awkward tables with seemingly byzantine rules for combining them. Take the first element of the first row, first element of the first column, multiply them together, then add... If that isn't strange I don't know what is.

 We all probably learned how to operate on them at some point but how did someone come up with the idea of matrices and the rules for operating on them? In short, what's the underlying intuition for matrices?

I really think these questions are worth answering as we use matrices in almost every field of engineering but often lack an intuition for them. To me it's not too different from applying multiplication tables without fully appreciating what numbers are.

So let's build this intuition! Through this post, I'm going to share my understanding of matrices and why I think they represent such a powerful idea.

## Linear Maps

Before delving into matrices, we need to first start with Linear Maps. Linear Maps are the foundations of matrices. Here's a simple example of a linear map:

* $f(x) = 3x$ for real numbers $x$.

Linear maps are functions that have these basic rules (I'm simplifying a little here. If you wan't the precise definition, see [here](https://en.wikipedia.org/wiki/Linear_map).) 

1. $ f(c \cdot x) = c \cdot f(x) $
   * You can multiply by a scalar before or after applying the function and get the same result.
   * For our example function, $f(5\cdot x) = 3 \cdot 5x = 15x = 5 \cdot f(x)$.
2. $ f(x+y) = f(x) + f(y) $
   * You can add before or after applying the function and get the same result.
   * For our example function, $f(x + y) = 3 \cdot (x + y) = 3x + 3y = f(x) + f(y)$.

Early mathematicians realized that such functions can model a lot of the phenomena that happen in the real world from physics, to statistics. Here are a few other examples of linear functions in geometry:
* Rotations
   * Functions that rotate shapes around a point.
   * ![rotation example](https://upload.wikimedia.org/wikipedia/commons/thumb/8/87/Rotation_illustration2.svg/1920px-Rotation_illustration2.svg.png).
* Scalings
   * Functions that takes a 2d image and scale their width and/or height.
   * ![scaling example](https://developer.apple.com/library/archive/documentation/Cocoa/Conceptual/CocoaDrawingGuide/Art/scaling_2x.png)

## Representing Functions
So we now know what linear functions are and we've seen how they represent many physical phenomena - but how can we represent them? Taking a step back, how do we represent functions in general?

One way is to simply have a table that takes every input and displays its output. For instance, for a function $f$ we could write:

|  $x$  |  $f(x)$ |
:----:|:------:
|  1  |  2  |
|  2  |  4  |
|  3  |  6  |

But this can much more easily be written as $f(x) = 2x$. This representation, a polynomial, is powerful. How? For example let's say I have another function $g(x) = 10x$. Imagine someone asks me, “what happens if I apply $f$, followed by $g$?"

Before I had this representation, I would have had to make a full table where I write out f(x), and then apply g(x) on it per input like below:

|  $x$  |  $f(x)$ |  $g(f(x))$ |
:----:|:---:|:------------:|
|  1  |  2  |      20    |
|  2  |  4  |      40    |
|  3  |  6  |      60    |

But now that we have a the polynomial representation, we can just do
$$g(x) = 10x$$
$$g(f(x)) = 10\cdot f(x)$$
$$g(f(x)) = 10\cdot 2x$$
$$g(f(x)) = 20x$$

In a few simple steps, we could immediately figure out $g(f(x))$. The same is true of $g(x) + f(x)$ etc.

In short, the right representation allows us to understand, combine, and process functions in extremely powerful ways.

### Representing Linear Functions

Returning to linear functions, how can we easily represent them equally succinctly?

#### 1-dimension

Let's start with linear functions that take in real numbers and return real numbers (all in 1 dimension - the real line).

<p class='image-block'>
<img src="https://upload.wikimedia.org/wikipedia/commons/2/2b/Real_number_line_for_Algebra_book.svg">
Let's start with linear functions that take inputs on the real line and return outputs on the real line
</p>

These linear transforms can always be written simply as $f(x) = mx$ for some $m$. Pretty simple!

#### 2-dimensions

But what about in 2 dimensions (i.e. the input is a vector $\begin{bmatrix}
1 \\ 0 \end{bmatrix}$)?

<p class='image-block'>
<img src="https://i.stack.imgur.com/TKyga.png"/>
Now, let's focus on linear functions that operate on 2d vectors.
</p>


Let's take a new function $f(x)$.
Let’s just start by describing what the function does to two of the most basic vectors $\begin{bmatrix}
1 \\
0
\end{bmatrix}$ and 
$\begin{bmatrix}
0 \\
1
\end{bmatrix}$.

We define:

$$f(\begin{bmatrix}
1 \\
0
\end{bmatrix}) = \begin{bmatrix}
3 \\
0
\end{bmatrix}$$
$$f(\begin{bmatrix}
0 \\
1
\end{bmatrix}) = \begin{bmatrix}
0 \\
5
\end{bmatrix}$$

Based on this, can we figure out $f\begin{bmatrix}
10 \\
9\end{bmatrix}$ is? Amazingly, yes!

------

The below diagram is going to show our approach visually:

<p class='image-block'>
<img src="/public/images/vector_img.png"/>
We will decompose $\begin{bmatrix} 10 \\ 9\end{bmatrix}$ into a combination of $\begin{bmatrix} 1 \\ 0\end{bmatrix})$ and $\begin{bmatrix} 0 \\1\end{bmatrix})$ (the two vectors which we know the value of $f$ for).
</p>

More precisely, here's how we find the final value: 

$$f(\begin{bmatrix}
10 \\
9\end{bmatrix}) = f(\begin{bmatrix}
10 \\
0\end{bmatrix}) + f(\begin{bmatrix}
0 \\
9\end{bmatrix})$$

$$ = 10 \cdot f(\begin{bmatrix}
1 \\
0
\end{bmatrix}) + 9 \cdot f(\begin{bmatrix} 0 \\ 1 \end{bmatrix})$$
$$ = 10 \cdot \begin{bmatrix} 3 \\ 0 \end{bmatrix} + 9\cdot \begin{bmatrix} 0 \\ 5 \end{bmatrix}$$
$$ = \begin{bmatrix} 30 \\ 0 \end{bmatrix} + \begin{bmatrix} 0 \\ 45 \end{bmatrix}$$
$$ = \begin{bmatrix}
30 \\
45
\end{bmatrix}$$


So we're able to find $f(\begin{bmatrix}
10 \\
9\end{bmatrix})$ by just knowing $f(\begin{bmatrix} 1 \\ 0\end{bmatrix})$ and $f(\begin{bmatrix} 0 \\ 1\end{bmatrix})$.

**In fact this is true more generally - we can represent the function entirely by what it does to the vectors $\begin{bmatrix}
1 \\
0
\end{bmatrix}$ and 
$\begin{bmatrix}
0 \\
1
\end{bmatrix}$ and use that to find all potential outputs!**


### Matrices

So is there a way I can succinctly say what a linear function does to $\begin{bmatrix}
1 \\
0
\end{bmatrix}$ and 
$\begin{bmatrix}
0 \\
1
\end{bmatrix}$?

Yes! A simple 2x2 matrix!


$f(x)$ (as we defined it in the previous section) can be represented by the notation
$$\begin{bmatrix} f(\begin{bmatrix} 1 \\ 0 \end{bmatrix}) & f(\begin{bmatrix} 0 \\ 1 \end{bmatrix}) \end{bmatrix}$$
$$ = \begin{bmatrix} 3 & 0 \\ 0 & 5 \end{bmatrix} $$

In this notation, the first column of the matrix is $f(\begin{bmatrix} 1 \\ 0 \end{bmatrix})$ and the second column is $f(\begin{bmatrix} 0 \\ 1 \end{bmatrix})$. This is extremely cool - we can describe the entire function and how it operates on an infinite number of points by a little 4 value table.


So just like whenever you see $f(x) = 2x + 3$, you immediately know you’re dealing with a function, **when you see a matrix, know that you are dealing with a linear function**.

### Applying the Function
Ok so we know we can represent a linear function as a matrix - but how do we apply this function on an input?

Specifically, say I have the same function $f$ which we described by the matrix $F =  \begin{bmatrix} 3 & 0 \\ 0 & 5 \end{bmatrix} $. I want to apply this function on the vector $ \begin{bmatrix} x \\ y \end{bmatrix} $. How do we do it?

------

Let’s start with what we know:

1. The first column of the matrix tells us $f(\begin{bmatrix} 1 \\ 0 \end{bmatrix})$ .
2. the second column tells us $f(\begin{bmatrix} 0 \\ 1 \end{bmatrix})$.


To make use of that, let's break $\begin{bmatrix} x \\ y \end{bmatrix}$ into a combination of $\begin{bmatrix} 1 \\ 0 \end{bmatrix}$ and $\begin{bmatrix} 0 \\ 1 \end{bmatrix}$.

$$\begin{bmatrix} x \\ y \end{bmatrix} = x \cdot \begin{bmatrix} 1 \\ 0 \end{bmatrix} + y \cdot \begin{bmatrix} 0 \\ 1 \end{bmatrix}$$

$$ f(\begin{bmatrix} x \\ y \end{bmatrix}) = f(x \cdot \begin{bmatrix} 1 \\ 0 \end{bmatrix}) + y \cdot \begin{bmatrix} 0 \\ 1 \end{bmatrix})$$

Thanks to the amazing properties of linear functions ($f(a+b) = f(a) + f(b)$), we can now simplify this to:

$$ = f(x \cdot \begin{bmatrix} 1 \\ 0 \end{bmatrix}) + f(y \cdot \begin{bmatrix} 0 \\ 1 \end{bmatrix})$$

And then using another property of linear functions ($f(c \cdot a) = c\cdot f(a)$),

$$ = x\cdot f(\begin{bmatrix} 1 \\ 0 \end{bmatrix}) + y \cdot f(\begin{bmatrix} 0 \\ 1 \end{bmatrix})$$

And now we apply the knowledge we have (from the columns of the matrix)!

$$ = x \cdot \begin{bmatrix} 3 \\ 0 \end{bmatrix} + y\cdot \begin{bmatrix} 0 \\ 5 \end{bmatrix}$$
$$f(\begin{bmatrix} x \\ y \end{bmatrix}) = \begin{bmatrix} 3x + 0y \\ 0x + 5y \end{bmatrix}$$

Does this look familiar? Because it is exactly what you would get by carrying out the matrix multiplication $\begin{bmatrix} 3 & 0 \\ 0 & 5 \end{bmatrix} \cdot \begin{bmatrix} x \\ y \end{bmatrix}$!

**The matrix multiplication rule is just a shorthand for applying a function on a vector!**

### Matrix Multiplication as Function Composition

Ok so we’ve seen that multiplying a 2x2 matrix by a vector is just applying the function on the vector. But what does matrix multiplication when we are multiplying two 2x2 matrices?

---------

To answer this, we’re going to take a small detour. We know how to apply a function $f$ on an input vector $v$. What if I ask you to find the composition $h = g(f(v))$ where we know $f$ and $g$?

Let’s work through this now:

Let $G = \begin{bmatrix} 5 & 9 \\ 1 & 6 \end{bmatrix}$ (G is the matrix for the function g).

Let $F = \begin{bmatrix} 3 & 0 \\ 0 & 5 \end{bmatrix}$ as before.


We want to find the matrix $H$ that represents the function $h = g(f(v))$.

This is going to be:

$$H = \begin{bmatrix} g(f(\begin{bmatrix} 1 \\ 0 \end{bmatrix}) & g(f(\begin{bmatrix} 0 \\ 1 \end{bmatrix})) \end{bmatrix}$$

Let $F_{col1}$ be the first column of $F$ and let $F_{col2}$ be the second column.

Then we can simplify to:

$$H = \begin{bmatrix} g(F_{col1}) & g(F_{col2}) \end{bmatrix} $$

So what’s $g(F_{col1})$?

Well we just saw in the function application section that this is just $G \cdot F_{col1}$. So we can now write:

$$H = \begin{bmatrix} G \cdot F_{col1} & G \cdot F_{col2} \end{bmatrix} $$

Seem familiar? Because it’s exactly what the formula for the 2x2 matrix multiplication $H = G\cdot F$! So $H$, the matrix representing $g(f(x))$, is just $G\cdot F$. ** Clearly, matrix multiplication can be thought of as function composition.**

### Combining Functions

Remember how much power we gained by being able to represent a function as a polynomial? We were able to combine polynomials, compose them, multiply them - we now have all that same power for linear functions! We can compose them (matrix multiplication), add them (matrix addition), and invert them (matrix inversion) all by following some simple rules.

A more sophisticated way of saying this is we have an algebra on these functions (just like we have an algebra on integers etc.). **This is what linear algebra means - the ability to do combine and compose linear functions just as we combine and compose integers.**

Imagine doing all this with input-output tables! It would be hell. Instead, we can now operate on these complex functions and combine them in all kinds of ways and immediately know the resulting function.

### Looking Forward
So we’ve seen pretty clearly that matrices are just functions and that linear algebra is the study of combining linear functions.

Understanding this helps us perceive some of the key ideas of linear algebra in a new way. In the next post, we’re going to focus on eigenvectors and learn why they are so useful in playing with these functions.


{% endkatexmm %}