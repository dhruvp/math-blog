---
layout: post
title: PageRank
comments: false

---

{% katexmm %}

Welcome back! Last time we derived Eigenvectors and saw how useful they are in analyzing matrices we need to apply again and again. In this post, we're going to dive into one of the most famous applications of Eigenvectors - the original PageRank algorithm that allowed Google to create the world's best search engine!

By the end of this post, you'll:

1. Feel like you could have come up with PageRank yourself.
2. Understand how eigenvectors are central to PageRank.
3. See how central eigenvectors are to dynamic processes in general.

We're going to build out a hypothetical scenario and use that to motivate and derive PageRank. Ok enough talking - let's dive in!

### Making Friends

You just moved to a new city and you’re trying to make some new friends. You’re trying to figure out which new friends to hang out with in your free time. Trouble is you’re super busy and have very little free time! So you need to rank all these potential friends to prioritize which ones to chill with.

<p class='image-block'>
<img src='https://images2.minutemediacdn.com/image/upload/c_fill,w_912,h_516,f_auto,q_auto,g_auto/shape/cover/entertainment/5b2fefb9fae96f45b7000002.jpeg' />

This could be you!
</p>

In a moment of clarity you realize the following:

1. Friends you’re close with are probably going to hang out with people you’d like.
2. A person a lot of people call their friend is probably someone you want to be friends with.


You decide to use these two insights to create a scheme you in a moment of originality call **FriendRank**.

FriendRank gives a potential friend a score (FriendScore) based on:

1. How many people are friends with this person weighted by
2. How close you are to the people who are friends with them

<div class='image-block'>
    <img src='/public/images/pagerank/abstract_friends.jpg' />
    In the above picture, how close you are to a person is shown by the size of the circle. To find your friend score for potential friend $F$, you just add up how close you are to $A$, $C$, and $D$.
</div>

Let’s write this down as a formula. Let’s say the strength of the friendship between you and some person $p$ is $FS(p)$. Let $Friends(p)$ be the set of friends of $p$.

The FS (FriendScore) for a potential friend Fred is:

$$ FS(Fred) = \sum_{p \in Friends(Fred)} FS(p) $$

#### Calculating Our First Friend Score

Let’s work through an example. Say you have 4 potential friends:

1. Jimmy (closeness score - 5)
2. Maya (closeness score - 9)
3. Lisa (closeness score - 8)
4. Fred (?)


In this world, you’re really close to Maya (with a score of 9) and Lisa (8) but only kinda close to Jimmy (5). 

Only Jimmy and Maya are both friends with Fred.

Graphically, this is:

<div class='image-block'>
    <img src='/public/images/pagerank/fred_friends.jpg' />
    Only Jimmy and Maya claim to be friends with Fred. Lisa seems to be <a href='https://www.youtube.com/watch?v=ptmM-m7Cl8U'>tearing him apart</a>.
</div>

So:
$$ FS(Fred) = FS(Jimmy) + FS(Maya)$$
$$FS(Fred) = 8 + 9 = 17$$

#### Accounting For People who are Friends With Everyone

Not such a crazy idea right? You start this process and you realize one thing. Your really close friend Maya calims to  be friends with EVERYONE. You start wondering, "Hmm maybe I need to downweight Maya’s opinion because she doesn’t really seem to be that picky”.

This is easy - we just divide Maya’s weighting score by how many people she claims to be friends with. That way if Maya claims 100 friends, his weighting for each friend is divided by 100. So our formula is now:

$$ FS(Fred) = \sum_{p \in Friends(Fred)} FS(p) \cdot \frac{1}{NumFriends(p)} $$


Going back to our example, our score becomes:
$$FS(Fred) = \frac{FS(Jimmy)}{2} + \frac{FS(Maya)}{4}$$
$$FS(Fred) = 4 + \frac{9}{4} = 6.25$$


Awesome!

Let’s now simplify this formula a little.
1. Let’s call the set of all friends $F$.
2. Let $IsFriends(p, Fred)$ be $1$ if $p$ and $Fred$ are friends and $0$ otherwise. Then, the above formula is equivalent to:

$$FS(Fred) = \sum_{p \in F} FS(p) \cdot \frac{IsFriends(p, Fred)}{NumFriends(p)}$$

All the people who aren’t friends with Fred just get $0$ terms which gives us the same thing.

{% endkatexmm %}

#### Time For Action!

<div class='image-block'>
    <img src='https://imgix.bustle.com/uploads/image/2018/10/1/8d493251-8b78-4cb3-a1be-b4ffb9cef4af-mean_girls_pink.png?w=1020&h=574&fit=crop&crop=faces&auto=format&q=70'/>
    It's time to find out who's really "friends" with whom.
</div>

Ok this is looking great! You decide to go ahead and implement this scheme with your friends Bobby, Lauren, Daniel, Rony, and Saba. You start by asking all your friends to write down who they’re friends with! So you send them all the following email:

<blockquote>
    <div>
        My dearest "friends",
    </div>
    <br/>
    <div>
    I’m trying to rank you and all my other potential friends and need your help to do so. Below is a list of people. Please put a 1 next to their name if you call them your friend.
    </div>
    <div>
        Bobby    ___
    </div>
    <div>
        Lauren   ___
    </div>
    <div>
        Daniel    ___
    </div>
    <div>
        Rony      ___
    </div>
    <div>
        Saba      ___
    </div>
    <br/>
    <div>
        Yours truly,
    </div>
    <br />
    <div>
        Parry Lage
    </div>
    <br />
    <div>
        P.S. Just because I'm sending you this email doesn't mean we're friends.
    </div>
</blockquote>

So Saba sends you something like this:

Bobby    _1__

Lauren   _1__

Daniel   _0__

Rony     _0__

Saba     _0__

Looking good so far! You then remember you need to downweight Saba’s score by how many friends she claims to have. She’s claiming 2 friends here so we divide by 2 giving us:

Bobby    _1/2__
Lauren   _1/2__
Daniel     _0__
Rony       _0__
Saba       _0__


Sweet.

You now decide to organize all your friends responses into a little table so that it’s easy to see. Each column of the table is a different friend. It looks like this:



Bobby
Lauren
Daniel
Rony
Saba
Bobby
0
1
1/3
0
1/2
Lauren
1/4
0
1/3
0
1/2
Daniel
1/4
0
0
0
0
Rony
1/4
0
0
0
0
Saba
1/4
0
1/3
1
0

This table is just a matrix. The element ij in the matrix is Is_Friends(i, j)/NumFriends(i).

You then realize you have to take the quiz yourself! There are some people you know better than others so this is really a guess for what your final FriendScore is for each of them. Here’s what you write down:

Bobby    _1/5__
Lauren   _1/5__
Daniel    _1/5__
Rony      _1/5__
Saba      _1/5__

Once you find out everyone else’s opinions, you’ll update your scores (because who doesn’t get influenced by their friends?). How do we do that?

Remember that F is the set of friends and FS_f(p) is the FriendScore for person f from friend p (i.e. how close person p is to f). Ideally we want to update our rankings to be:

Bobby    _ \sum_{p \in F} FS(p) \cdot \frac{Is_Friends(p, Bobby)}{NumFriends(p)}_
Lauren   _ \sum_{p \in F} FS(p) \cdot \frac{Is_Friends(p, Lauren)}{NumFriends(p)}__
Daniel    _ \sum_{p \in F} FS(p) \cdot \frac{Is_Friends(p, Daniel)}{NumFriends(p)}__
Rony      _ \sum_{p \in F} FS(p) \cdot \frac{Is_Friends(p, Rony)}{NumFriends(p)}__
Saba      _ \sum_{p \in F} FS(p) \cdot \frac{Is_Friends(p, Saba)}{NumFriends(p)}__

Let’s just look at Bobby’s ideal new ranking: 
\sum_{p \in F} FS(p) \cdot \frac{Is_Friends(p, Bobby)}{NumFriends(p)}

This looks an awful lot like a dot product, or just:

[Is_Frends(Bobby, Bobby)/NumFriends(Bobby) Is_Friends(Lauren, Bobby)/NumFriends(Lauren) … ] [...]

And now notice the following:
The first row of A is exactly [Is_Frends(Bobby, Bobby)/NumFriends(Bobby) Is_Friends(Lauren, Bobby)/NumFriends(Lauren) … ] 
Your rankings, or FS, is exactly the second vector [...]

Similarly, if we move to Lauren, we want her ideal score to be: 

[Is_Frends(Bobby, Lauren)/NumFriends(Bobby) Is_Friends(Lauren,Lauren)/NumFriends(Lauren) … ] [...]

And again:
The second row of A is exactly [Is_Frends(Bobby, Lauren)/NumFriends(Bobby) Is_Friends(Lauren,Lauren)/NumFriends(Lauren) … ]
Your rankings, FS, is exactly the second vector [...]

So if we just multiply A*FS we get [...]. This is exactly what we want!
Ok so we now have a super quick way of finding our friend scores. Just take our current guess, which we’ll call FS_i, multiply it by A, and this will give us FS_{i+1}

FS_{i+1} = A * FS_{i}

Everytime we compute A*FS{i}, we are updating our guess of our Friend Score with the rest of our friends opinions.

When do we stop this process? We stop when FS_{i+1} = FS{i} = FS*. At this point,
FS* = A x FS*

This is exactly the formula for an eigenvector! Does this look like Ax = \lambda x? Yes!

So the final solution FS*, is an eigenvector of A!

Visually

How does FS_i move to FS*? In many ways, the matrix A pulls FS_i towards its eigenvector FS*. There’s an awesome visualization of this here by setosa.io that I highly recommend you check out. Here’s an extract directly from their writeup.



What’s happening is that as you keep multiplying FS_i by A, A starts pulling FS_i towards its eigenvectors FS*. At the end of the process, A x FS* just remains on FS* and the process converges.


The matrix A (Rey?!) pulls its inputs (the saber) towards its eigenvectors (hand?).

The Solution to FriendRank

Therefore, the solution to FriendRank is to just find the eigenvector of A.

From Friends to Pages

You’ve probably guessed at this point that you can switch the word friends to pages in the above and get PageRank! In the world of webpages, one webpage claims to be “friends” with another if it links out to the webpage.

Google finds out who’s friends with who (our initial survey) by just crawling the web and finding out who links to who.

Insert example of doing this process there

So PageRank is really a great way to model how we rank people in real life!

A quick aside, notice that PageRank is actually a next level pun - PageRank was written by Larry Page about ranking webpages - well done Larry.

Conclusion

So we’ve seen that eigenvectors are at the heart of one of the most important algorithms of all time! More generally, whenever you see a linear function being applied again and again and again (Like A), you are without a doubt going to be looking for the eigenvectors of that linear function/matrix. The eigenvectors will tell you where that process send its inputs in the end!


